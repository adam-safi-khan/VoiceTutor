Some thoughts on Alaris Project
Hi! I’m Adam, and I study Computer Science & Philosophy here at Oxford University.
So much of what we do here is discussion-based: whether critiquing probability approaches to find the most elegant way to count groups of people; or debating Descartes with your Philosophy tutor to understand whether you can truly trust your senses. 
The ability to think out loud, listen analytically, and learn and adapt in real time is vital – not just at university, but at all stages of academic, professional and personal life. 
I’ve always been lucky to be surrounded by family, friends, teachers, and mentors who took me seriously, took the time to explain things to me, and over time not just sharpened these skills – but did so in a way that made me really love thinking – and that seems to be a common trend here!
In fact, one of my favourite conversations was at Hall at college, when myself, a biologist, a physicist, and an economist were locked in a discussion on population collapse and birth rates – a conversation which went on until the staff repeatedly had to ask us to leave.   
I’ve always felt how much happier everyone might be, and how much better the world would look, if everyone had the same access to ‘thinking partners’ as I did – and right now, technology is just getting good enough to make this possible. Which is why I built Alaris, your lifelong ‘thinking partner’ – for learning, sparring, and interrogating the world around you. 
--
The process I envision is as follows:
-	The user, the first time they use the app, is NOT asked a bunch of survey-style questions. We know their age and country from auth, and that’s IT. 
-	When they click Start / Launch etc, they are greeted via voice with words to the effect of ‘Hi! I’ve got three ideas for what we could talk about today – is there one that you want to do over the rest?’ and then it’ll come up with other topics, so ‘One option is talking about the King, and the role they’ve had in governing the UK over time. Second, we could talk about solar power, and the science of recent improvements in efficiency. Third, we could talk about why people dream, and the leading theories behind them.’ 
-	The user will probably specify (or maybe equivocate and then the AI can pick); then the AI should be like ‘Awesome! Just so I know, do you know anything about this topic already? Totally fine (or stronger positive) if not – just so I don’t jump in to deep or start off too slowly.’
-	‘Finally – are there any of the other options you’re keen to revisit, maybe in a few days – or were you not too keen on them?’
-	Then, the AI will get to work building the lesson out. The conversation experience should be planned for about 30 minutes, and it should reveal itself over time.
-	The first question should be super easy and accessible, but also have room to really let the user talk; it should be open-ended. So something like, for the first option, ‘I’m going to ask a bit of an open-ended question to start, so just say what comes to mind: What do you know about the king?’ A kid with no idea might go ‘He wears a crown, I think he lives in a palace’; some expert historian might go on and on about the historical details; and these would both be perfectly acceptable answers. To some extent, the difficulty should have been anticipated in the question-building exercise, but the AI should adapt the rest of the conversation based on this. 
o	This question should NOT repeat what was said at the start, so if they – when asked what they know already – have already expanded on all of this, we should ask ‘except for X’ or ask them to go a little deeper in explaining what they’ve said. 
-	Then, the AI – either through follow-on questions or by a little bit of exposition – should go onto the curriculum / learning points it wanted to cover. The conversation should get progressively more rigorous, (of course if it’s clear the user is a super genius we just kind of go deeper at each point; and if it’s clear they’re struggling, we slow down and make sure they really enjoy and understand the conversation even if only a fraction of the planned content gets covered). It is natural for the conversation to go in different possible directions – largely this should be planned by the AI in advance, but the user will likely ask offshoot questions or the responses should lead the AI to ask follow-ups which go randomly off-piece. This is GREAT and should be anticipated and not punished!
-	Over the conversation, which should be somewhat like an Oxford interview or tutorial (but way friendlier), there are a number of different possible things that can happen:
o	AI asks the user how things might work / whether or not one option or another makes more sense and why (shouldn’t require actual contextual knowledge unless clear the user would have it; more posing a scenario)… this might be preceded by some setup: like ‘in 12__ the King held absolute power, which he often used to ____. Who do you think would have been upset by this – and if you were them, what would you have done?’ Can also be opinion based: ‘If you had the power to do X, (EITHER would you, or what would you consider before doing so, or what would be the reasons for and against)’; and then this all gets challenged / probed further – ‘but what about X? couldn’t you argue XYZ?’
o	User is asked to summarise arguments (and then perhaps provide a view): develop empathy / ability to put oneself in others’ shoes, that sort of thing. 
o	On more technical points: AI should explain things in a way that seems simple and intuitive, building up sequentially and at each step asking the user to summarise / explain what that means; adding depth to a mental model. 
